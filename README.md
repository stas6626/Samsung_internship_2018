# Samsung_internship_2018
NLP task
Привет!
Небольшое пояснение по заданию, что я делал. Я выполнял второе задание, а именно пункты 1 и 2.
Так как я не уверен в законности сбора датасета, на гит его я не выложу, но приложу ссылку, где его можно найти
https://drive.google.com/open?id=1D9dfo-ut3a4hkNtPX84UTJaSMRxW63Tn

Сбор датасета.
Я скачал кучу книг в формате pdf и djvu, переконвертировал все в txt шки через программу calibre, 
а потом собрал это все в csv-шник рекурсивным поиском, подробнее в Data_preparation.py, а так же я сделал upsampling.

Пункт 1

Метрика и валидация.
это самый сложный и непонятный пункт, т.к. бить на валидацию(и тест), а так же выбирать метрику нужно исходя из "Бизнес" задачи, или реальной ситуации, 
ну к примеру, есть книга, и нам нужно понять чья она, тогда нужно тренироваться на одних книгах и предсказывать на других.
В там случае нужно будет делать модель устойчивой(dropout-ы) накидывать etc. 
Я подумал, что в тестовом задании для стажеров главное наглядность, по-этому валидировался по случайным предложениям, а метрика accuracy[1]

Модель.
Ну я взял модель, которая хорошо отработала в  toxic challenge, ну может немного поменял слоев и параметры подобрал.
В итоге вышел Embending Fasttext-ом -> 2 layer GRU -> 2 layer convolution(kernel = 3) -> 
-> сконкатенировал max_global_pooling и average_global_pooling c последних слоев gru и conv -> 2 полносвязных слоя-> сигмоида
Оптимизировал binary_crossentropy Adam-ом
Точность на train-e, val-e, test-e = 0.9676, 0.96381, 0.96213 (Графики есть в )

Пункт 2

Предложения которые мог сказать и Гегель и Гоголь, по мнению моей модели. В файле train.ipynb я вывел строки из тестового подмножества, которые модель предсказала 0.5 +-eps
Как я и предполагал, сюда попали предложения со странными артефактами djvu и pdf reader-ов. Типа этого - "Гов орили с ним о Малорос сийской Истории". 
Фразы вырванные из контекста и фразы общего назначения: "Но то было давно." или "А доказательство в наше время."
Ну и сноски и другие примечания(от авторов или редакций), которые я не знаю как выцеплять таким варварским методом типа "37, 226— 240, May 1928." или "Примечание 4 Непостижимость начала"

Что нужно было бы еще сделать. 
Заменять все цифры токенами (я забыл об этом)


Пункт 3 я не выполнял, тк моя модель для этого совсем не подходит, а придумывать под эту задачу новую, мне оч не хотелось:/


[1] Когда отправлял задание, я понял, что у меня сильный лик из-за upsampling-a :((( Я все резко переучил и актуализировал accuracy
